optimizer:
  _target_: torch.optim.Adam
  lr: 0.001
  weight_decay: 0.0001

scheduler:
    _target_: torch.optim.lr_scheduler.StepLR
    step_size: 50
    gamma: 0.1

loss:
  _target_: torch.nn.CrossEntropyLoss